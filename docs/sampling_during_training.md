> ğŸ“ Click on the language section to expand / è¨€èªã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹

# Sampling during training / å­¦ç¿’ä¸­ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ

By preparing a prompt file, you can generate sample images during training.

Please be aware that it consumes a considerable amount of VRAM, so be careful when generating sample images for videos with a large number of frames. Also, since it takes time to generate, adjust the frequency of sample image generation as needed.

<details>
<summary>æ—¥æœ¬èª</summary>

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã™ã‚‹ã“ã¨ã§ã€å­¦ç¿’ä¸­ã«ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

VRAMã‚’ãã‚Œãªã‚Šã«æ¶ˆè²»ã—ã¾ã™ã®ã§ã€ç‰¹ã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒå¤šã„å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹å ´åˆã¯æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã¾ãŸç”Ÿæˆã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã®ã§ã€ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆã®é »åº¦ã¯é©å®œèª¿æ•´ã—ã¦ãã ã•ã„ã€‚
</details>

## How to use / ä½¿ã„æ–¹

### Command line options for training with sampling / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆã«é–¢é€£ã™ã‚‹å­¦ç¿’æ™‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³

Example of command line options for training with sampling / è¨˜è¿°ä¾‹:  

```bash
--vae path/to/ckpts/hunyuan-video-t2v-720p/vae/pytorch_model.pt 
--vae_chunk_size 32 --vae_spatial_tile_sample_min_size 128
--text_encoder1 path/to/ckpts/text_encoder 
--text_encoder2 path/to/ckpts/text_encoder_2 
--sample_prompts /path/to/prompt_file.txt 
--sample_every_n_epochs 1 --sample_every_n_steps 1000 -- sample_at_first
```

`--vae`, `--vae_chunk_size`, `--vae_spatial_tile_sample_min_size`, `--text_encoder1`, `--text_encoder2` are the same as when generating images, so please refer to [here](/README.md#inference) for details. `--fp8_llm` can also be specified.

`--sample_prompts` specifies the path to the prompt file used for sample image generation. Details are described below.

`--sample_every_n_epochs` specifies how often to generate sample images in epochs, and `--sample_every_n_steps` specifies how often to generate sample images in steps.

`--sample_at_first` is specified when generating sample images at the beginning of training.

Sample images and videos are saved in the `sample` directory in the directory specified by `--output_dir`. They are saved as `.png` for still images and `.mp4` for videos.

<details>
<summary>æ—¥æœ¬èª</summary>

`--vae`ã€`--vae_chunk_size`ã€`--vae_spatial_tile_sample_min_size`ã€`--text_encoder1`ã€`--text_encoder2`ã¯ã€ç”»åƒç”Ÿæˆæ™‚ã¨åŒæ§˜ã§ã™ã®ã§ã€è©³ç´°ã¯[ã“ã¡ã‚‰](/README.ja.md#æ¨è«–)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚`--fp8_llm`ã‚‚æŒ‡å®šå¯èƒ½ã§ã™ã€‚

`--sample_prompts`ã¯ã€ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚è©³ç´°ã¯å¾Œè¿°ã—ã¾ã™ã€‚

`--sample_every_n_epochs`ã¯ã€ä½•ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‹ã‚’ã€`--sample_every_n_steps`ã¯ã€ä½•ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‹ã‚’æŒ‡å®šã—ã¾ã™ã€‚

`--sample_at_first`ã¯ã€å­¦ç¿’é–‹å§‹æ™‚ã«ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆã™ã‚‹å ´åˆã«æŒ‡å®šã—ã¾ã™ã€‚

ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã€å‹•ç”»ã¯ã€`--output_dir`ã§æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã€`sample`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚é™æ­¢ç”»ã®å ´åˆã¯`.png`ã€å‹•ç”»ã®å ´åˆã¯`.mp4`ã§ä¿å­˜ã•ã‚Œã¾ã™ã€‚
</details>

### Prompt file / ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«

The prompt file is a text file that contains the prompts for generating sample images. The example is as follows. / ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨˜è¿°ã—ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚ä¾‹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

```
# prompt 1: for generating a cat video
A cat walks on the grass, realistic style. --w 640 --h 480 --f 25 --d 1 --s 20

# prompt 2: for generating a dog image
A dog runs on the beach, realistic style. --w 960 --h 544 --f 1 --d 2 --s 20
```

A line starting with `#` is a comment.

* `--w` specifies the width of the generated image or video. The default is 256.
* `--h` specifies the height. The default is 256.
* `--f` specifies the number of frames. The default is 1, which generates a still image.
* `--d` specifies the seed. The default is random.
* `--s` specifies the number of steps in generation. The default is 20.
* `--g` specifies the guidance scale. The default is 6.0, which is the default value during inference of HunyuanVideo.
* `--fs` specifies the discrete flow shift. The default is 14.5, which corresponds to the number of steps 20. In the HunyuanVideo paper, 7.0 is recommended for 50 steps, and 17.0 is recommended for less than 20 steps (e.g. 10).

<details>
<summary>æ—¥æœ¬èª</summary>

`#` ã§å§‹ã¾ã‚‹è¡Œã¯ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚

* `--w` ç”Ÿæˆç”»åƒã€å‹•ç”»ã®å¹…ã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯256ã§ã™ã€‚
* `--h` é«˜ã•ã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯256ã§ã™ã€‚
* `--f` ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯1ã§ã€é™æ­¢ç”»ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
* `--d` ã‚·ãƒ¼ãƒ‰ã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ã§ã™ã€‚
* `--s` ç”Ÿæˆã«ãŠã‘ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯20ã§ã™ã€‚
* `--g` guidance scaleã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯6.0ã§ã€HunyuanVideoã®æ¨è«–æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã™ã€‚
* `--fs` discrete flow shiftã‚’æŒ‡å®šã—ã¾ã™ã€‚çœç•¥æ™‚ã¯14.5ã§ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°20ã®å ´åˆã«å¯¾å¿œã—ãŸå€¤ã§ã™ã€‚HunyuanVideoã®è«–æ–‡ã§ã¯ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°50ã®å ´åˆã¯7.0ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°20æœªæº€ï¼ˆ10ãªã©ï¼‰ã§17.0ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
</details>