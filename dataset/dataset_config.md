> ğŸ“ Click on the language section to expand / è¨€èªã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹

## Dataset Configuration

<details>
<summary>English</summary>

Please create a TOML file for dataset configuration.

Image and video datasets are supported. The configuration file can include multiple datasets, either image or video datasets, with caption text files or metadata JSONL files.

The cache directory must be different for each dataset.
</details>

<details>
<summary>æ—¥æœ¬èª</summary>

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨­å®šã‚’è¡Œã†ãŸã‚ã®TOMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€ç”»åƒã¾ãŸã¯å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¤‡æ•°å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã€å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«ç•°ãªã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
</details>

### Sample for Image Dataset with Caption Text Files

```toml
# resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets
# otherwise, the default values will be used for each item

# general configurations
[general]
resolution = [960, 544]
caption_extension = ".txt"
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
image_directory = "/path/to/image_dir"
cache_directory = "/path/to/cache_directory"
num_repeats = 1 # optional, default is 1. Number of times to repeat the dataset. Useful to balance the multiple datasets with different sizes.

# other datasets can be added here. each dataset can have different configurations
```

<details>
<summary>English</summary>

`cache_directory` is optional, default is None to use the same directory as the image directory. However, we recommend to set the cache directory to avoid accidental sharing of the cache files between different datasets.

`num_repeats` is also available. It is optional, default is 1 (no repeat). It repeats the images (or videos) that many times to expand the dataset. For example, if `num_repeats = 2` and there are 20 images in the dataset, each image will be duplicated twice (with the same caption) to have a total of 40 images. It is useful to balance the multiple datasets with different sizes.

</details>

<details>
<summary>æ—¥æœ¬èª</summary>

`cache_directory` ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è¨­å®šã•ã‚Œã¾ã™ã€‚ãŸã ã—ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…±æœ‰ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã«ã€æ˜ç¤ºçš„ã«åˆ¥ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

`num_repeats` ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 1 ã§ã™ï¼ˆç¹°ã‚Šè¿”ã—ãªã—ï¼‰ã€‚ç”»åƒï¼ˆã‚„å‹•ç”»ï¼‰ã‚’ã€ãã®å›æ•°ã ã‘å˜ç´”ã«ç¹°ã‚Šè¿”ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã—ã¾ã™ã€‚ãŸã¨ãˆã°`num_repeats = 2`ã¨ã—ãŸã¨ãã€ç”»åƒ20æšã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªã‚‰ã€å„ç”»åƒãŒ2æšãšã¤ï¼ˆåŒä¸€ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã§ï¼‰è¨ˆ40æšå­˜åœ¨ã—ãŸå ´åˆã¨åŒã˜ã«ãªã‚Šã¾ã™ã€‚ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ä½¿ç”¨å¯èƒ½ã§ã™ã€‚

resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale ã¯ general ã¾ãŸã¯ datasets ã®ã©ã¡ã‚‰ã‹ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚çœç•¥æ™‚ã¯å„é …ç›®ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

`[[datasets]]`ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã§ãã¾ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ç•°ãªã‚‹è¨­å®šã‚’æŒã¦ã¾ã™ã€‚
</details>

### Sample for Image Dataset with Metadata JSONL File

```toml
# resolution, batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets
# caption_extension is not required for metadata jsonl file
# cache_directory is required for each dataset with metadata jsonl file

# general configurations
[general]
resolution = [960, 544]
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
image_jsonl_file = "/path/to/metadata.jsonl"
cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
num_repeats = 1 # optional, default is 1. Same as above.

# other datasets can be added here. each dataset can have different configurations
```

JSONL file format for metadata:

```json
{"image_path": "/path/to/image1.jpg", "caption": "A caption for image1"}
{"image_path": "/path/to/image2.jpg", "caption": "A caption for image2"}
```

<details>
<summary>æ—¥æœ¬èª</summary>

resolution, batch_size, num_repeats, enable_bucket, bucket_no_upscale ã¯ general ã¾ãŸã¯ datasets ã®ã©ã¡ã‚‰ã‹ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚çœç•¥æ™‚ã¯å„é …ç›®ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

metadata jsonl ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€caption_extension ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã€cache_directory ã¯å¿…é ˆã§ã™ã€‚

ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒæ§˜ã«ã€è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã§ãã¾ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ç•°ãªã‚‹è¨­å®šã‚’æŒã¦ã¾ã™ã€‚
</details>


### Sample for Video Dataset with Caption Text Files

```toml
# resolution, caption_extension, target_frames, frame_extraction, frame_stride, frame_sample, 
# batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets
# num_repeats is also available for video dataset, example is not shown here

# general configurations
[general]
resolution = [960, 544]
caption_extension = ".txt"
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
video_directory = "/path/to/video_dir"
cache_directory = "/path/to/cache_directory" # recommended to set cache directory
target_frames = [1, 25, 45]
frame_extraction = "head"

# other datasets can be added here. each dataset can have different configurations
```

<details>
<summary>æ—¥æœ¬èª</summary>

resolution, caption_extension, target_frames, frame_extraction, frame_stride, frame_sample, batch_size, num_repeats, enable_bucket, bucket_no_upscale ã¯ general ã¾ãŸã¯ datasets ã®ã©ã¡ã‚‰ã‹ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

ä»–ã®æ³¨æ„äº‹é …ã¯ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒæ§˜ã§ã™ã€‚
</details>

### Sample for Video Dataset with Metadata JSONL File

```toml
# resolution, target_frames, frame_extraction, frame_stride, frame_sample, 
# batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets
# caption_extension is not required for metadata jsonl file
# cache_directory is required for each dataset with metadata jsonl file

# general configurations
[general]
resolution = [960, 544]
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl"
target_frames = [1, 25, 45]
frame_extraction = "head"
cache_directory = "/path/to/cache_directory_head"

# same metadata jsonl file can be used for multiple datasets
[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl"
target_frames = [1]
frame_stride = 10
cache_directory = "/path/to/cache_directory_stride"

# other datasets can be added here. each dataset can have different configurations
```

JSONL file format for metadata:

```json
{"video_path": "/path/to/video1.mp4", "caption": "A caption for video1"}
{"video_path": "/path/to/video2.mp4", "caption": "A caption for video2"}
```

<details>
<summary>æ—¥æœ¬èª</summary>

resolution, target_frames, frame_extraction, frame_stride, frame_sample, batch_size, num_repeats, enable_bucket, bucket_no_upscale ã¯ general ã¾ãŸã¯ datasets ã®ã©ã¡ã‚‰ã‹ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

metadata jsonl ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€caption_extension ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã€cache_directory ã¯å¿…é ˆã§ã™ã€‚

ä»–ã®æ³¨æ„äº‹é …ã¯ä»Šã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒæ§˜ã§ã™ã€‚
</details>

### frame_extraction Options

<details>
<summary>English</summary>

- `head`: Extract the first N frames from the video.
- `chunk`: Extract frames by splitting the video into chunks of N frames.
- `slide`: Extract frames from the video with a stride of `frame_stride`.
- `uniform`: Extract `frame_sample` samples uniformly from the video.

For example, consider a video with 40 frames. The following diagrams illustrate each extraction:
</details>

<details>
<summary>æ—¥æœ¬èª</summary>

- `head`: å‹•ç”»ã‹ã‚‰æœ€åˆã®Nãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `chunk`: å‹•ç”»ã‚’Nãƒ•ãƒ¬ãƒ¼ãƒ ãšã¤ã«åˆ†å‰²ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `slide`: `frame_stride`ã«æŒ‡å®šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«å‹•ç”»ã‹ã‚‰Nãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `uniform`: å‹•ç”»ã‹ã‚‰ä¸€å®šé–“éš”ã§ã€`frame_sample`å€‹ã®Nãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

ä¾‹ãˆã°ã€40ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‹•ç”»ã‚’ä¾‹ã¨ã—ãŸæŠ½å‡ºã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å›³ã§èª¬æ˜ã—ã¾ã™ã€‚
</details>

```
Original Video, 40 frames: x = frame, o = no frame
oooooooooooooooooooooooooooooooooooooooo

head, target_frames = [1, 13, 25] -> extract head frames:
xooooooooooooooooooooooooooooooooooooooo
xxxxxxxxxxxxxooooooooooooooooooooooooooo
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo

chunk, target_frames = [13, 25] -> extract frames by splitting into chunks, into 13 and 25 frames:
xxxxxxxxxxxxxooooooooooooooooooooooooooo
oooooooooooooxxxxxxxxxxxxxoooooooooooooo
ooooooooooooooooooooooooooxxxxxxxxxxxxxo
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo

NOTE: Please do not include 1 in target_frames if you are using the frame_extraction "chunk". It will make the all frames to be extracted.
æ³¨: frame_extraction "chunk" ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€target_frames ã« 1 ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚å…¨ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæŠ½å‡ºã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚

slide, target_frames = [1, 13, 25], frame_stride = 10 -> extract N frames with a stride of 10:
xooooooooooooooooooooooooooooooooooooooo
ooooooooooxooooooooooooooooooooooooooooo
ooooooooooooooooooooxooooooooooooooooooo
ooooooooooooooooooooooooooooooxooooooooo
xxxxxxxxxxxxxooooooooooooooooooooooooooo
ooooooooooxxxxxxxxxxxxxooooooooooooooooo
ooooooooooooooooooooxxxxxxxxxxxxxooooooo
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo
ooooooooooxxxxxxxxxxxxxxxxxxxxxxxxxooooo

uniform, target_frames =[1, 13, 25], frame_sample = 4 -> extract `frame_sample` samples uniformly, N frames each:
xooooooooooooooooooooooooooooooooooooooo
oooooooooooooxoooooooooooooooooooooooooo
oooooooooooooooooooooooooxoooooooooooooo
ooooooooooooooooooooooooooooooooooooooox
xxxxxxxxxxxxxooooooooooooooooooooooooooo
oooooooooxxxxxxxxxxxxxoooooooooooooooooo
ooooooooooooooooooxxxxxxxxxxxxxooooooooo
oooooooooooooooooooooooooooxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo
oooooxxxxxxxxxxxxxxxxxxxxxxxxxoooooooooo
ooooooooooxxxxxxxxxxxxxxxxxxxxxxxxxooooo
oooooooooooooooxxxxxxxxxxxxxxxxxxxxxxxxx
```

## Specifications

```toml
# general configurations
[general]
resolution = [960, 544] # optional, [W, H], default is None. This is the default resolution for all datasets
caption_extension = ".txt" # optional, default is None. This is the default caption extension for all datasets
batch_size = 1 # optional, default is 1. This is the default batch size for all datasets
num_repeats = 1 # optional, default is 1. Number of times to repeat the dataset. Useful to balance the multiple datasets with different sizes.
enable_bucket = true # optional, default is false. Enable bucketing for datasets
bucket_no_upscale = false # optional, default is false. Disable upscaling for bucketing. Ignored if enable_bucket is false

### Image Dataset

# sample image dataset with caption text files
[[datasets]]
image_directory = "/path/to/image_dir"
caption_extension = ".txt" # required for caption text files, if general caption extension is not set
resolution = [960, 544] # required if general resolution is not set
batch_size = 4 # optional, overwrite the default batch size
num_repeats = 1 # optional, overwrite the default num_repeats
enable_bucket = false # optional, overwrite the default bucketing setting
bucket_no_upscale = true # optional, overwrite the default bucketing setting
cache_directory = "/path/to/cache_directory" # optional, default is None to use the same directory as the image directory. NOTE: caching is always enabled

# sample image dataset with metadata **jsonl** file
[[datasets]]
image_jsonl_file = "/path/to/metadata.jsonl" # includes pairs of image files and captions
resolution = [960, 544] # required if general resolution is not set
cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
# caption_extension is not required for metadata jsonl file
# batch_size, num_repeats, enable_bucket, bucket_no_upscale are also available for metadata jsonl file

### Video Dataset

# sample video dataset with caption text files
[[datasets]]
video_directory = "/path/to/video_dir"
caption_extension = ".txt" # required for caption text files, if general caption extension is not set
resolution = [960, 544] # required if general resolution is not set

target_frames = [1, 25, 79] # required for video dataset. list of video lengths to extract frames. each element must be N*4+1 (N=0,1,2,...)

# NOTE: Please do not include 1 in target_frames if you are using the frame_extraction "chunk". It will make the all frames to be extracted.

frame_extraction = "head" # optional, "head" or "chunk", "slide", "uniform". Default is "head"
frame_stride = 1 # optional, default is 1, available for "slide" frame extraction
frame_sample = 4 # optional, default is 1 (same as "head"), available for "uniform" frame extraction
# batch_size, num_repeats, enable_bucket, bucket_no_upscale, cache_directory are also available for video dataset

# sample video dataset with metadata jsonl file
[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl" # includes pairs of video files and captions

target_frames = [1, 79]

cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
# frame_extraction, frame_stride, frame_sample are also available for metadata jsonl file
```

<!-- 
# sample image dataset with lance
[[datasets]]
image_lance_dataset = "/path/to/lance_dataset"
resolution = [960, 544] # required if general resolution is not set
# batch_size, enable_bucket, bucket_no_upscale, cache_directory are also available for lance dataset
-->

The metadata with .json file will be supported in the near future.



<!--

```toml
# general configurations
[general]
resolution = [960, 544] # optional, [W, H], default is None. This is the default resolution for all datasets
caption_extension = ".txt" # optional, default is None. This is the default caption extension for all datasets
batch_size = 1 # optional, default is 1. This is the default batch size for all datasets
enable_bucket = true # optional, default is false. Enable bucketing for datasets
bucket_no_upscale = false # optional, default is false. Disable upscaling for bucketing. Ignored if enable_bucket is false

# sample image dataset with caption text files
[[datasets]]
image_directory = "/path/to/image_dir"
caption_extension = ".txt" # required for caption text files, if general caption extension is not set
resolution = [960, 544] # required if general resolution is not set
batch_size = 4 # optional, overwrite the default batch size
enable_bucket = false # optional, overwrite the default bucketing setting
bucket_no_upscale = true # optional, overwrite the default bucketing setting
cache_directory = "/path/to/cache_directory" # optional, default is None to use the same directory as the image directory. NOTE: caching is always enabled

# sample image dataset with metadata **jsonl** file
[[datasets]]
image_jsonl_file = "/path/to/metadata.jsonl" # includes pairs of image files and captions
resolution = [960, 544] # required if general resolution is not set
cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
# caption_extension is not required for metadata jsonl file
# batch_size, enable_bucket, bucket_no_upscale are also available for metadata jsonl file

# sample video dataset with caption text files
[[datasets]]
video_directory = "/path/to/video_dir"
caption_extension = ".txt" # required for caption text files, if general caption extension is not set
resolution = [960, 544] # required if general resolution is not set
target_frames = [1, 25, 79] # required for video dataset. list of video lengths to extract frames. each element must be N*4+1 (N=0,1,2,...)
frame_extraction = "head" # optional, "head" or "chunk", "slide", "uniform". Default is "head"
frame_stride = 1 # optional, default is 1, available for "slide" frame extraction
frame_sample = 4 # optional, default is 1 (same as "head"), available for "uniform" frame extraction
# batch_size, enable_bucket, bucket_no_upscale, cache_directory are also available for video dataset

# sample video dataset with metadata jsonl file
[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl" # includes pairs of video files and captions
target_frames = [1, 79]
cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
# frame_extraction, frame_stride, frame_sample are also available for metadata jsonl file
```

# sample image dataset with lance
[[datasets]]
image_lance_dataset = "/path/to/lance_dataset"
resolution = [960, 544] # required if general resolution is not set
# batch_size, enable_bucket, bucket_no_upscale, cache_directory are also available for lance dataset

The metadata with .json file will be supported in the near future.




-->