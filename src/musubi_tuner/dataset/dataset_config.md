> ğŸ“ Click on the language section to expand / è¨€èªã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹

## Dataset Configuration

Please create a TOML file for dataset configuration.

Image and video datasets are supported. The configuration file can include multiple datasets, either image or video datasets, with caption text files or metadata JSONL files.

The cache directory must be different for each dataset.

Each video is extracted frame by frame without additional processing and used for training. It is recommended to use videos with a frame rate of 24fps for HunyuanVideo, 16fps for Wan2.1 and 30fps for FramePack. You can check the videos that will be trained using `--debug_mode video` when caching latent (see [here](/README.md#latent-caching)).
<details>
<summary>æ—¥æœ¬èª</summary>

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨­å®šã‚’è¡Œã†ãŸã‚ã®TOMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€ç”»åƒã¾ãŸã¯å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¤‡æ•°å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã€å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«ç•°ãªã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

å‹•ç”»ã¯è¿½åŠ ã®ãƒ—ãƒ­ã‚»ã‚¹ãªã—ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«æŠ½å‡ºã•ã‚Œã€å­¦ç¿’ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚ãã®ãŸã‚ã€HunyuanVideoã¯24fpsã€Wan2.1ã¯16fpsã€FramePackã¯30fpsã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã®å‹•ç”»ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚latentã‚­ãƒ£ãƒƒã‚·ãƒ¥æ™‚ã®`--debug_mode video`ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å­¦ç¿’ã•ã‚Œã‚‹å‹•ç”»ã‚’ç¢ºèªã§ãã¾ã™ï¼ˆ[ã“ã¡ã‚‰](/README.ja.md#latentã®äº‹å‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥)ã‚’å‚ç…§ï¼‰ã€‚
</details>

### Sample for Image Dataset with Caption Text Files

```toml
# resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets
# otherwise, the default values will be used for each item

# general configurations
[general]
resolution = [960, 544]
caption_extension = ".txt"
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
image_directory = "/path/to/image_dir"
cache_directory = "/path/to/cache_directory"
num_repeats = 1 # optional, default is 1. Number of times to repeat the dataset. Useful to balance the multiple datasets with different sizes.

# other datasets can be added here. each dataset can have different configurations
```

`cache_directory` is optional, default is None to use the same directory as the image directory. However, we recommend to set the cache directory to avoid accidental sharing of the cache files between different datasets.

`num_repeats` is also available. It is optional, default is 1 (no repeat). It repeats the images (or videos) that many times to expand the dataset. For example, if `num_repeats = 2` and there are 20 images in the dataset, each image will be duplicated twice (with the same caption) to have a total of 40 images. It is useful to balance the multiple datasets with different sizes.

<details>
<summary>æ—¥æœ¬èª</summary>

`cache_directory` ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è¨­å®šã•ã‚Œã¾ã™ã€‚ãŸã ã—ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…±æœ‰ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã«ã€æ˜ç¤ºçš„ã«åˆ¥ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

`num_repeats` ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 1 ã§ã™ï¼ˆç¹°ã‚Šè¿”ã—ãªã—ï¼‰ã€‚ç”»åƒï¼ˆã‚„å‹•ç”»ï¼‰ã‚’ã€ãã®å›æ•°ã ã‘å˜ç´”ã«ç¹°ã‚Šè¿”ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã—ã¾ã™ã€‚ãŸã¨ãˆã°`num_repeats = 2`ã¨ã—ãŸã¨ãã€ç”»åƒ20æšã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªã‚‰ã€å„ç”»åƒãŒ2æšãšã¤ï¼ˆåŒä¸€ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã§ï¼‰è¨ˆ40æšå­˜åœ¨ã—ãŸå ´åˆã¨åŒã˜ã«ãªã‚Šã¾ã™ã€‚ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ä½¿ç”¨å¯èƒ½ã§ã™ã€‚

resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale ã¯ general ã¾ãŸã¯ datasets ã®ã©ã¡ã‚‰ã‹ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚çœç•¥æ™‚ã¯å„é …ç›®ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

`[[datasets]]`ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã§ãã¾ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ç•°ãªã‚‹è¨­å®šã‚’æŒã¦ã¾ã™ã€‚
</details>

### Sample for Image Dataset with Metadata JSONL File

```toml
# resolution, batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets
# caption_extension is not required for metadata jsonl file
# cache_directory is required for each dataset with metadata jsonl file

# general configurations
[general]
resolution = [960, 544]
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
image_jsonl_file = "/path/to/metadata.jsonl"
cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
num_repeats = 1 # optional, default is 1. Same as above.

# other datasets can be added here. each dataset can have different configurations
```

JSONL file format for metadata:

```json
{"image_path": "/path/to/image1.jpg", "caption": "A caption for image1"}
{"image_path": "/path/to/image2.jpg", "caption": "A caption for image2"}
```

<details>
<summary>æ—¥æœ¬èª</summary>

resolution, batch_size, num_repeats, enable_bucket, bucket_no_upscale ã¯ general ã¾ãŸã¯ datasets ã®ã©ã¡ã‚‰ã‹ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚çœç•¥æ™‚ã¯å„é …ç›®ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

metadata jsonl ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€caption_extension ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã€cache_directory ã¯å¿…é ˆã§ã™ã€‚

ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒæ§˜ã«ã€è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã§ãã¾ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ç•°ãªã‚‹è¨­å®šã‚’æŒã¦ã¾ã™ã€‚
</details>


### Sample for Video Dataset with Caption Text Files

```toml
# Common parameters (resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale) 
# can be set in either general or datasets sections
# Video-specific parameters (target_frames, frame_extraction, frame_stride, frame_sample, max_frames, source_fps)
# must be set in each datasets section

# general configurations
[general]
resolution = [960, 544]
caption_extension = ".txt"
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
video_directory = "/path/to/video_dir"
cache_directory = "/path/to/cache_directory" # recommended to set cache directory
target_frames = [1, 25, 45]
frame_extraction = "head"
source_fps = 30.0 # optional, source fps for videos in the directory, decimal number

[[datasets]]
video_directory = "/path/to/video_dir2"
cache_directory = "/path/to/cache_directory2" # recommended to set cache directory
frame_extraction = "full"
max_frames = 45

# other datasets can be added here. each dataset can have different configurations
```

__In HunyuanVideo and Wan2.1, the number of `target_frames` must be "N\*4+1" (N=0,1,2,...).__ Otherwise, it will be truncated to the nearest "N*4+1".

In FramePack, it is recommended to set `frame_extraction` to `full` and `max_frames` to a sufficiently large value, as it can handle longer videos. However, if the video is too long, an Out of Memory error may occur during VAE encoding. The videos in FramePack are trimmed to "N * latent_window_size * 4 + 1" frames (for example, 37, 73, 109... if `latent_window_size` is 9).

If the `source_fps` is specified, the videos in the directory are considered to be at this frame rate, and some frames will be skipped to match the model's frame rate (24 for HunyuanVideo and 16 for Wan2.1). __The value must be a decimal number, for example, `30.0` instead of `30`.__ The skipping is done automatically and does not consider the content of the images. Please check if the converted data is correct using `--debug_mode video`.

If `source_fps` is not specified (default), all frames of the video will be used regardless of the video's frame rate.

<details>
<summary>æ—¥æœ¬èª</summary>

å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆresolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscaleï¼‰ã¯ã€generalã¾ãŸã¯datasetsã®ã„ãšã‚Œã‹ã«è¨­å®šã§ãã¾ã™ã€‚
å‹•ç”»å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆtarget_frames, frame_extraction, frame_stride, frame_sample, max_frames, source_fpsï¼‰ã¯ã€å„datasetsã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

__HunyuanVideoãŠã‚ˆã³Wan2.1ã§ã¯ã€target_framesã®æ•°å€¤ã¯ã€ŒN\*4+1ã€ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚__ ã“ã‚Œä»¥å¤–ã®å€¤ã®å ´åˆã¯ã€æœ€ã‚‚è¿‘ã„N\*4+1ã®å€¤ã«åˆ‡ã‚Šæ¨ã¦ã‚‰ã‚Œã¾ã™ã€‚

FramePackã§ã‚‚åŒæ§˜ã§ã™ãŒã€FramePackã§ã¯å‹•ç”»ãŒé•·ãã¦ã‚‚å­¦ç¿’å¯èƒ½ãªãŸã‚ã€ `frame_extraction`ã«`full` ã‚’æŒ‡å®šã—ã€`max_frames`ã‚’ååˆ†ã«å¤§ããªå€¤ã«è¨­å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ãŸã ã—ã€ã‚ã¾ã‚Šã«ã‚‚é•·ã™ãã‚‹ã¨VAEã®encodeã§Out of Memoryã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚FramePackã®å‹•ç”»ã¯ã€ã€ŒN * latent_window_size * 4 + 1ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãƒˆãƒªãƒŸãƒ³ã‚°ã•ã‚Œã¾ã™ï¼ˆlatent_window_sizeãŒ9ã®å ´åˆã€37ã€73ã€109â€¦â€¦ï¼‰ã€‚

`source_fps`ã‚’æŒ‡å®šã—ãŸå ´åˆã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å‹•ç”»ã‚’ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã¨ã¿ãªã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã«ã‚ã†ã‚ˆã†ã«ã„ãã¤ã‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼ˆHunyuanVideoã¯24ã€Wan2.1ã¯16ï¼‰ã€‚__å°æ•°ç‚¹ã‚’å«ã‚€æ•°å€¤ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚__ ä¾‹ï¼š`30`ã§ã¯ãªã`30.0`ã€‚ã‚¹ã‚­ãƒƒãƒ—ã¯æ©Ÿæ¢°çš„ã«è¡Œã‚ã‚Œã€ç”»åƒã®å†…å®¹ã¯è€ƒæ…®ã—ã¾ã›ã‚“ã€‚å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ã„ã‹ã€`--debug_mode video`ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚

`source_fps`ã‚’æŒ‡å®šã—ãªã„å ´åˆã€å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ï¼ˆå‹•ç”»è‡ªä½“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã«é–¢ä¿‚ãªãï¼‰ã™ã¹ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

ä»–ã®æ³¨æ„äº‹é …ã¯ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒæ§˜ã§ã™ã€‚
</details>

### Sample for Video Dataset with Metadata JSONL File

```toml
# Common parameters (resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale) 
# can be set in either general or datasets sections
# Video-specific parameters (target_frames, frame_extraction, frame_stride, frame_sample, max_frames, source_fps)
# must be set in each datasets section

# caption_extension is not required for metadata jsonl file
# cache_directory is required for each dataset with metadata jsonl file

# general configurations
[general]
resolution = [960, 544]
batch_size = 1
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl"
target_frames = [1, 25, 45]
frame_extraction = "head"
cache_directory = "/path/to/cache_directory_head"
source_fps = 30.0 # optional, source fps for videos in the jsonl file
# same metadata jsonl file can be used for multiple datasets
[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl"
target_frames = [1]
frame_stride = 10
cache_directory = "/path/to/cache_directory_stride"

# other datasets can be added here. each dataset can have different configurations
```

JSONL file format for metadata:

```json
{"video_path": "/path/to/video1.mp4", "caption": "A caption for video1"}
{"video_path": "/path/to/video2.mp4", "caption": "A caption for video2"}
```

`video_path` can be a directory containing multiple images.

<details>
<summary>æ—¥æœ¬èª</summary>
metadata jsonl ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€caption_extension ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã€cache_directory ã¯å¿…é ˆã§ã™ã€‚

`video_path`ã¯ã€è¤‡æ•°ã®ç”»åƒã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

ä»–ã®æ³¨æ„äº‹é …ã¯ä»Šã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åŒæ§˜ã§ã™ã€‚
</details>

### frame_extraction Options

- `head`: Extract the first N frames from the video.
- `chunk`: Extract frames by splitting the video into chunks of N frames.
- `slide`: Extract frames from the video with a stride of `frame_stride`.
- `uniform`: Extract `frame_sample` samples uniformly from the video.
- `full`: Extract all frames from the video.

In the case of `full`, the entire video is used, but it is trimmed to "N*4+1" frames. It is also trimmed to the `max_frames` if it exceeds that value. To avoid Out of Memory errors, please set `max_frames`.

The frame extraction methods other than `full` are recommended when the video contains repeated actions. `full` is recommended when each video represents a single complete motion.

For example, consider a video with 40 frames. The following diagrams illustrate each extraction:

<details>
<summary>æ—¥æœ¬èª</summary>

- `head`: å‹•ç”»ã‹ã‚‰æœ€åˆã®Nãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `chunk`: å‹•ç”»ã‚’Nãƒ•ãƒ¬ãƒ¼ãƒ ãšã¤ã«åˆ†å‰²ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `slide`: `frame_stride`ã«æŒ‡å®šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«å‹•ç”»ã‹ã‚‰Nãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `uniform`: å‹•ç”»ã‹ã‚‰ä¸€å®šé–“éš”ã§ã€`frame_sample`å€‹ã®Nãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
- `full`: å‹•ç”»ã‹ã‚‰å…¨ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

`full`ã®å ´åˆã€å„å‹•ç”»ã®å…¨ä½“ã‚’ç”¨ã„ã¾ã™ãŒã€ã€ŒN*4+1ã€ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«ãƒˆãƒªãƒŸãƒ³ã‚°ã•ã‚Œã¾ã™ã€‚ã¾ãŸ`max_frames`ã‚’è¶…ãˆã‚‹å ´åˆã‚‚ãã®å€¤ã«ãƒˆãƒªãƒŸãƒ³ã‚°ã•ã‚Œã¾ã™ã€‚Out of Memoryã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€`max_frames`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

`full`ä»¥å¤–ã®æŠ½å‡ºæ–¹æ³•ã¯ã€å‹•ç”»ãŒç‰¹å®šã®å‹•ä½œã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ã‚‹å ´åˆã«ãŠå‹§ã‚ã—ã¾ã™ã€‚`full`ã¯ãã‚Œãã‚Œã®å‹•ç”»ãŒã²ã¨ã¤ã®å®Œçµã—ãŸãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã®å ´åˆã«ãŠå‹§ã‚ã—ã¾ã™ã€‚

ä¾‹ãˆã°ã€40ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‹•ç”»ã‚’ä¾‹ã¨ã—ãŸæŠ½å‡ºã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å›³ã§èª¬æ˜ã—ã¾ã™ã€‚
</details>

```
Original Video, 40 frames: x = frame, o = no frame
oooooooooooooooooooooooooooooooooooooooo

head, target_frames = [1, 13, 25] -> extract head frames:
xooooooooooooooooooooooooooooooooooooooo
xxxxxxxxxxxxxooooooooooooooooooooooooooo
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo

chunk, target_frames = [13, 25] -> extract frames by splitting into chunks, into 13 and 25 frames:
xxxxxxxxxxxxxooooooooooooooooooooooooooo
oooooooooooooxxxxxxxxxxxxxoooooooooooooo
ooooooooooooooooooooooooooxxxxxxxxxxxxxo
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo

NOTE: Please do not include 1 in target_frames if you are using the frame_extraction "chunk". It will make the all frames to be extracted.
æ³¨: frame_extraction "chunk" ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€target_frames ã« 1 ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚å…¨ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæŠ½å‡ºã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚

slide, target_frames = [1, 13, 25], frame_stride = 10 -> extract N frames with a stride of 10:
xooooooooooooooooooooooooooooooooooooooo
ooooooooooxooooooooooooooooooooooooooooo
ooooooooooooooooooooxooooooooooooooooooo
ooooooooooooooooooooooooooooooxooooooooo
xxxxxxxxxxxxxooooooooooooooooooooooooooo
ooooooooooxxxxxxxxxxxxxooooooooooooooooo
ooooooooooooooooooooxxxxxxxxxxxxxooooooo
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo
ooooooooooxxxxxxxxxxxxxxxxxxxxxxxxxooooo

uniform, target_frames =[1, 13, 25], frame_sample = 4 -> extract `frame_sample` samples uniformly, N frames each:
xooooooooooooooooooooooooooooooooooooooo
oooooooooooooxoooooooooooooooooooooooooo
oooooooooooooooooooooooooxoooooooooooooo
ooooooooooooooooooooooooooooooooooooooox
xxxxxxxxxxxxxooooooooooooooooooooooooooo
oooooooooxxxxxxxxxxxxxoooooooooooooooooo
ooooooooooooooooooxxxxxxxxxxxxxooooooooo
oooooooooooooooooooooooooooxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxooooooooooooooo
oooooxxxxxxxxxxxxxxxxxxxxxxxxxoooooooooo
ooooooooooxxxxxxxxxxxxxxxxxxxxxxxxxooooo
oooooooooooooooxxxxxxxxxxxxxxxxxxxxxxxxx

Three Original Videos, 20, 25, 35 frames: x = frame, o = no frame

full, max_frames = 31 -> extract all frames (trimmed to the maximum length):
video1: xxxxxxxxxxxxxxxxx (trimmed to 17 frames)
video2: xxxxxxxxxxxxxxxxxxxxxxxxx (25 frames)
video3: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx (trimmed to 31 frames)
```

### Sample for Image Dataset with Control Images

The dataset with control images. This is used for training the one frame training for FramePack.

The dataset configuration with caption text files is similar to the image dataset, but with an additional `control_directory` parameter.

The control images are used from the `control_directory` with the same filename (or different extension) as the image, for example, `image_dir/image1.jpg` and `control_dir/image1.png`. The images in `image_directory` should be the target images (the images to be generated during inference, the changed images). The `control_directory` should contain the starting images for inference. The captions should be stored in `image_directory`.

If multiple control images are specified, the filenames of the control images should be numbered (excluding the extension). For example, specify `image_dir/image1.jpg` and `control_dir/image1_0.png`, `control_dir/image1_1.png`. You can also specify the numbers with four digits, such as `image1_0000.png`, `image1_0001.png`.

The metadata JSONL file format is the same as the image dataset, but with an additional `control_path` parameter.

```json
{"image_path": "/path/to/image1.jpg", "control_path": "/path/to/control1.png", "caption": "A caption for image1"}
{"image_path": "/path/to/image2.jpg", "control_path": "/path/to/control2.png", "caption": "A caption for image2"}

If multiple control images are specified, the attribute names should be `control_path_0`, `control_path_1`, etc.

```json
{"image_path": "/path/to/image1.jpg", "control_path_0": "/path/to/control1_0.png", "control_path_1": "/path/to/control1_1.png", "caption": "A caption for image1"}
{"image_path": "/path/to/image2.jpg", "control_path_0": "/path/to/control2_0.png", "control_path_1": "/path/to/control2_1.png", "caption": "A caption for image2"}
```

The control images can also have an alpha channel. In this case, the alpha channel of the image is used as a mask for the latent.

<details>
<summary>æ—¥æœ¬èª</summary>

åˆ¶å¾¡ç”»åƒã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚ç¾æ™‚ç‚¹ã§ã¯FramePackã®å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ å­¦ç¿’ã«ä½¿ç”¨ã—ã¾ã™ã€‚

ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨ã„ã‚‹å ´åˆã¯`control_directory`ã‚’è¿½åŠ ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚åˆ¶å¾¡ç”»åƒã¯ã€ç”»åƒã¨åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆã¾ãŸã¯æ‹¡å¼µå­ã®ã¿ãŒç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã®ã€`control_directory`ã«ã‚ã‚‹ç”»åƒãŒä½¿ç”¨ã•ã‚Œã¾ã™ï¼ˆä¾‹ï¼š`image_dir/image1.jpg`ã¨`control_dir/image1.png`ï¼‰ã€‚`image_directory`ã®ç”»åƒã¯å­¦ç¿’å¯¾è±¡ã®ç”»åƒï¼ˆæ¨è«–æ™‚ã«ç”Ÿæˆã™ã‚‹ç”»åƒã€å¤‰åŒ–å¾Œã®ç”»åƒï¼‰ã¨ã—ã¦ãã ã•ã„ã€‚`control_directory`ã«ã¯æ¨è«–æ™‚ã®é–‹å§‹ç”»åƒã‚’æ ¼ç´ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¯`image_directory`ã¸æ ¼ç´ã—ã¦ãã ã•ã„ã€‚

è¤‡æ•°æšã®åˆ¶å¾¡ç”»åƒãŒæŒ‡å®šå¯èƒ½ã§ã™ã€‚ã“ã®å ´åˆã€åˆ¶å¾¡ç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ã‚’é™¤ãï¼‰ã¸æ•°å­—ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€`image_dir/image1.jpg`ã¨`control_dir/image1_0.png`, `control_dir/image1_1.png`ã®ã‚ˆã†ã«æŒ‡å®šã—ã¾ã™ã€‚`image1_0000.png`, `image1_0001.png`ã®ã‚ˆã†ã«æ•°å­—ã‚’4æ¡ã§æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€`control_path`ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚è¤‡æ•°æšã®åˆ¶å¾¡ç”»åƒã‚’æŒ‡å®šã™ã‚‹å ´åˆã¯ã€`control_path_0`, `control_path_1`ã®ã‚ˆã†ã«æ•°å­—ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚

åˆ¶å¾¡ç”»åƒã¯ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’æŒã¤ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã®å ´åˆã€ç”»åƒã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ã¯latentã¸ã®ãƒã‚¹ã‚¯ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

</details>

### Sample for Video Dataset with Control Images

The dataset with control videos is used for training ControlNet models. 

The dataset configuration with caption text files is similar to the video dataset, but with an additional `control_directory` parameter. 

The control video for a video is used from the `control_directory` with the same filename (or different extension) as the video, for example, `video_dir/video1.mp4` and `control_dir/video1.mp4` or `control_dir/video1.mov`. The control video can also be a directory without an extension, for example, `video_dir/video1.mp4` and `control_dir/video1`.

```toml
[[datasets]]
video_directory = "/path/to/video_dir"
control_directory = "/path/to/control_dir" # required for dataset with control videos
cache_directory = "/path/to/cache_directory" # recommended to set cache directory
target_frames = [1, 25, 45]
frame_extraction = "head"
```

The dataset configuration with metadata JSONL file is  same as the video dataset, but metadata JSONL file must include the control video paths. The control video path can be a directory containing multiple images.

```json
{"video_path": "/path/to/video1.mp4", "control_path": "/path/to/control1.mp4", "caption": "A caption for video1"}
{"video_path": "/path/to/video2.mp4", "control_path": "/path/to/control2.mp4", "caption": "A caption for video2"}
```

<details>
<summary>æ—¥æœ¬èª</summary>

åˆ¶å¾¡å‹•ç”»ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚ControlNetãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã—ã¾ã™ã€‚

ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”¨ã„ã‚‹å ´åˆã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã¯å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ä¼¼ã¦ã„ã¾ã™ãŒã€`control_directory`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸Šã«ã‚ã‚‹ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ã‚ã‚‹å‹•ç”»ã«å¯¾ã™ã‚‹åˆ¶å¾¡ç”¨å‹•ç”»ã¨ã—ã¦ã€å‹•ç”»ã¨åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆã¾ãŸã¯æ‹¡å¼µå­ã®ã¿ãŒç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã®ã€`control_directory`ã«ã‚ã‚‹å‹•ç”»ãŒä½¿ç”¨ã•ã‚Œã¾ã™ï¼ˆä¾‹ï¼š`video_dir/video1.mp4`ã¨`control_dir/video1.mp4`ã¾ãŸã¯`control_dir/video1.mov`ï¼‰ã€‚ã¾ãŸã€æ‹¡å¼µå­ãªã—ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã€è¤‡æ•°æšã®ç”»åƒã‚’åˆ¶å¾¡ç”¨å‹•ç”»ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ï¼ˆä¾‹ï¼š`video_dir/video1.mp4`ã¨`control_dir/video1`ï¼‰ã€‚

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€å‹•ç”»ã¨åˆ¶å¾¡ç”¨å‹•ç”»ã®ãƒ‘ã‚¹ã‚’å«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚åˆ¶å¾¡ç”¨å‹•ç”»ã®ãƒ‘ã‚¹ã¯ã€è¤‡æ•°æšã®ç”»åƒã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

</details>

## Architecture-specific Settings / ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›ºæœ‰ã®è¨­å®š

The dataset configuration is shared across all architectures. However, some architectures may require additional settings or have specific requirements for the dataset.

### FramePack

For FramePack, you can set the latent window size for training. It is recommended to set it to 9 for FramePack training. The default value is 9, so you can usually omit this setting.

```toml
[[datasets]]
fp_latent_window_size = 9
```

<details>
<summary>æ—¥æœ¬èª</summary>

å­¦ç¿’æ™‚ã®latent window sizeã‚’æŒ‡å®šã§ãã¾ã™ã€‚FramePackã®å­¦ç¿’ã«ãŠã„ã¦ã¯ã€9ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚çœç•¥æ™‚ã¯9ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã®ã§ã€é€šå¸¸ã¯çœç•¥ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚

</details>

### FramePack One Frame Training

For the default one frame training of FramePack, you need to set the following parameters in the dataset configuration:

```toml
[[datasets]]
fp_1f_clean_indices = [0]
fp_1f_target_index = 9
fp_1f_no_post = false
```

**Advanced Settings:**

**Note that these parameters are still experimental, and the optimal values are not yet known.** The parameters may also change in the future.

`fp_1f_clean_indices` sets the `clean_indices` value passed to the FramePack model. You can specify multiple indices. `fp_1f_target_index` sets the index of the frame to be trained (generated). `fp_1f_no_post` sets whether to add a zero value as `clean_latent_post`, default is `false` (add zero value).

The number of control images should match the number of indices specified in `fp_1f_clean_indices`.

The default values mean that the first image (control image) is at index `0`, and the target image (the changed image) is at index `9`.

For training with 1f-mc, set `fp_1f_clean_indices` to `[0, 1]` and `fp_1f_target_index` to `9` (or another value). This allows you to use multiple control images to train a single generated image. The control images will be two in this case.

```toml
[[datasets]]
fp_1f_clean_indices = [0, 1]
fp_1f_target_index = 9
fp_1f_no_post = false
```

For training with kisekaeichi, set `fp_1f_clean_indices` to `[0, 10]` and `fp_1f_target_index` to `1` (or another value). This allows you to use the starting image (the image just before the generation section) and the image following the generation section (equivalent to `clean_latent_post`) to train the first image of the generated video. The control images will be two in this case. `fp_1f_no_post` should be set to `true`.

```toml
[[datasets]]
fp_1f_clean_indices = [0, 10]
fp_1f_target_index = 1
fp_1f_no_post = true
```

With `fp_1f_clean_indices` and `fp_1f_target_index`, you can specify any number of control images and any index of the target image for training.

If you set `fp_1f_no_post` to `false`, the `clean_latent_post_index` will be `1 + fp1_latent_window_size`.

You can also set the `no_2x` and `no_4x` options for cache scripts to disable the clean latents 2x and 4x.

The 2x indices are `1 + fp1_latent_window_size + 1` for two indices (usually `11, 12`), and the 4x indices are `1 + fp1_latent_window_size + 1 + 2` for sixteen indices (usually `13, 14, ..., 28`), regardless of `fp_1f_no_post` and `no_2x`, `no_4x` settings.

<details>
<summary>æ—¥æœ¬èª</summary>

â€» **ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ç ”ç©¶ä¸­ã§æœ€é©å€¤ã¯ã¾ã ä¸æ˜ã§ã™ã€‚** ã¾ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªä½“ã‚‚å¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®1ãƒ•ãƒ¬ãƒ¼ãƒ å­¦ç¿’ã‚’è¡Œã†å ´åˆã€`fp_1f_clean_indices`ã«`[0]`ã‚’ã€`fp_1f_target_index`ã«`9`ï¼ˆã¾ãŸã¯5ã‹ã‚‰15ç¨‹åº¦ã®å€¤ï¼‰ã‚’ã€`no_post`ã«`false`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ï¼ˆè¨˜è¿°ä¾‹ã¯è‹±èªç‰ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã€ä»¥é™åŒã˜ã€‚ï¼‰

**ã‚ˆã‚Šé«˜åº¦ãªè¨­å®šï¼š**

`fp_1f_clean_indices`ã¯ã€FramePackãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã•ã‚Œã‚‹ `clean_indices` ã®å€¤ã‚’è¨­å®šã—ã¾ã™ã€‚è¤‡æ•°æŒ‡å®šãŒå¯èƒ½ã§ã™ã€‚`fp_1f_target_index`ã¯ã€å­¦ç¿’ï¼ˆç”Ÿæˆï¼‰å¯¾è±¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚`fp_1f_no_post`ã¯ã€`clean_latent_post` ã‚’ã‚¼ãƒ­å€¤ã§è¿½åŠ ã™ã‚‹ã‹ã©ã†ã‹ã‚’è¨­å®šã—ã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯`false`ã§ã€ã‚¼ãƒ­å€¤ã§è¿½åŠ ã—ã¾ã™ï¼‰ã€‚

åˆ¶å¾¡ç”»åƒã®æšæ•°ã¯`fp_1f_clean_indices`ã«æŒ‡å®šã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ•°ã¨ã‚ã‚ã›ã¦ãã ã•ã„ã€‚

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®1ãƒ•ãƒ¬ãƒ¼ãƒ å­¦ç¿’ã§ã¯ã€é–‹å§‹ç”»åƒï¼ˆåˆ¶å¾¡ç”»åƒï¼‰1æšã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹`0`ã€ç”Ÿæˆå¯¾è±¡ã®ç”»åƒï¼ˆå¤‰åŒ–å¾Œã®ç”»åƒï¼‰ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹`9`ã«è¨­å®šã—ã¦ã„ã¾ã™ã€‚

1f-mcã®å­¦ç¿’ã‚’è¡Œã†å ´åˆã¯ã€`fp_1f_clean_indices`ã« `[0, 1]`ã‚’ã€`fp_1f_target_index`ã«`9`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šå‹•ç”»ã®å…ˆé ­ã®2æšã®åˆ¶å¾¡ç”»åƒã‚’ä½¿ç”¨ã—ã¦ã€å¾Œç¶šã®1æšã®ç”Ÿæˆç”»åƒã‚’å­¦ç¿’ã—ã¾ã™ã€‚åˆ¶å¾¡ç”»åƒã¯2æšã«ãªã‚Šã¾ã™ã€‚

kisekaeichiã®å­¦ç¿’ã‚’è¡Œã†å ´åˆã¯ã€`fp_1f_clean_indices`ã« `[0, 10]`ã‚’ã€`fp_1f_target_index`ã«`1`ï¼ˆã¾ãŸã¯ä»–ã®å€¤ï¼‰ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯ã€é–‹å§‹ç”»åƒï¼ˆç”Ÿæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›´å‰ã®ç”»åƒï¼‰ï¼ˆ`clean_latent_pre`ã«ç›¸å½“ï¼‰ã¨ã€ç”Ÿæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ç¶šã1æšã®ç”»åƒï¼ˆ`clean_latent_post`ã«ç›¸å½“ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ç”Ÿæˆå‹•ç”»ã®å…ˆé ­ã®ç”»åƒï¼ˆ`target_index=1`ï¼‰ã‚’å­¦ç¿’ã—ã¾ã™ã€‚åˆ¶å¾¡ç”»åƒã¯2æšã«ãªã‚Šã¾ã™ã€‚`f1_1f_no_post`ã¯`true`ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

`fp_1f_clean_indices`ã¨`fp_1f_target_index`ã‚’å¿œç”¨ã™ã‚‹ã“ã¨ã§ã€ä»»æ„ã®æšæ•°ã®åˆ¶å¾¡ç”»åƒã‚’ã€ä»»æ„ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒ‡å®šã—ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚

`fp_1f_no_post`ã‚’`false`ã«è¨­å®šã™ã‚‹ã¨ã€`clean_latent_post_index`ã¯ `1 + fp1_latent_window_size` ã«ãªã‚Šã¾ã™ã€‚

æ¨è«–æ™‚ã® `no_2x`ã€`no_4x`ã«å¯¾å¿œã™ã‚‹è¨­å®šã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å¼•æ•°ã§è¡Œãˆã¾ã™ã€‚ãªãŠã€2xã®indexã¯ `1 + fp1_latent_window_size + 1` ã‹ã‚‰ã®2å€‹ï¼ˆé€šå¸¸ã¯`11, 12`ï¼‰ã€4xã®indexã¯ `1 + fp1_latent_window_size + 1 + 2` ã‹ã‚‰ã®16å€‹ã«ãªã‚Šã¾ã™ï¼ˆé€šå¸¸ã¯`13, 14, ..., 28`ï¼‰ã§ã™ã€‚ã“ã‚Œã‚‰ã®å€¤ã¯`fp_1f_no_post`ã‚„`no_2x`, `no_4x`ã®è¨­å®šã«é–¢ã‚ã‚‰ãšã€å¸¸ã«åŒã˜ã§ã™ã€‚

</details>

## Specifications

```toml
# general configurations
[general]
resolution = [960, 544] # optional, [W, H], default is [960, 544]. This is the default resolution for all datasets
caption_extension = ".txt" # optional, default is None. This is the default caption extension for all datasets
batch_size = 1 # optional, default is 1. This is the default batch size for all datasets
num_repeats = 1 # optional, default is 1. Number of times to repeat the dataset. Useful to balance the multiple datasets with different sizes.
enable_bucket = true # optional, default is false. Enable bucketing for datasets
bucket_no_upscale = false # optional, default is false. Disable upscaling for bucketing. Ignored if enable_bucket is false

### Image Dataset

# sample image dataset with caption text files
[[datasets]]
image_directory = "/path/to/image_dir"
caption_extension = ".txt" # required for caption text files, if general caption extension is not set
resolution = [960, 544] # required if general resolution is not set
batch_size = 4 # optional, overwrite the default batch size
num_repeats = 1 # optional, overwrite the default num_repeats
enable_bucket = false # optional, overwrite the default bucketing setting
bucket_no_upscale = true # optional, overwrite the default bucketing setting
cache_directory = "/path/to/cache_directory" # optional, default is None to use the same directory as the image directory. NOTE: caching is always enabled
control_directory = "/path/to/control_dir" # optional, required for dataset with control images

# sample image dataset with metadata **jsonl** file
[[datasets]]
image_jsonl_file = "/path/to/metadata.jsonl" # includes pairs of image files and captions
resolution = [960, 544] # required if general resolution is not set
cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
# caption_extension is not required for metadata jsonl file
# batch_size, num_repeats, enable_bucket, bucket_no_upscale are also available for metadata jsonl file

### Video Dataset

# sample video dataset with caption text files
[[datasets]]
video_directory = "/path/to/video_dir"
caption_extension = ".txt" # required for caption text files, if general caption extension is not set
resolution = [960, 544] # required if general resolution is not set

control_directory = "/path/to/control_dir" # optional, required for dataset with control images

# following configurations must be set in each [[datasets]] section for video datasets

target_frames = [1, 25, 79] # required for video dataset. list of video lengths to extract frames. each element must be N*4+1 (N=0,1,2,...)

# NOTE: Please do not include 1 in target_frames if you are using the frame_extraction "chunk". It will make the all frames to be extracted.

frame_extraction = "head" # optional, "head" or "chunk", "slide", "uniform". Default is "head"
frame_stride = 1 # optional, default is 1, available for "slide" frame extraction
frame_sample = 4 # optional, default is 1 (same as "head"), available for "uniform" frame extraction
max_frames = 129 # optional, default is 129. Maximum number of frames to extract, available for "full" frame extraction
# batch_size, num_repeats, enable_bucket, bucket_no_upscale, cache_directory are also available for video dataset

# sample video dataset with metadata jsonl file
[[datasets]]
video_jsonl_file = "/path/to/metadata.jsonl" # includes pairs of video files and captions

target_frames = [1, 79]

cache_directory = "/path/to/cache_directory" # required for metadata jsonl file
# frame_extraction, frame_stride, frame_sample, max_frames are also available for metadata jsonl file
```

<!-- 
# sample image dataset with lance
[[datasets]]
image_lance_dataset = "/path/to/lance_dataset"
resolution = [960, 544] # required if general resolution is not set
# batch_size, enable_bucket, bucket_no_upscale, cache_directory are also available for lance dataset
-->

The metadata with .json file will be supported in the near future.



